From 36d77500f64408f73495285f2d38dba6b8d2e0e6 Mon Sep 17 00:00:00 2001
From: Russell King <rmk+kernel@arm.linux.org.uk>
Date: Mon, 30 Nov 2015 11:39:14 +0000
Subject: [PATCH 189/195] staging: etnaviv: add a per-object mutex

Add a per-gem object mutex to protect each objects data.  This must be
held when changing ->pages, ->sgt, adding or removing MMU mappings, or
searching the vram list.

Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
---
 drivers/staging/etnaviv/etnaviv_drv.h        |  3 +-
 drivers/staging/etnaviv/etnaviv_dump.c       |  2 +-
 drivers/staging/etnaviv/etnaviv_gem.c        | 67 +++++++++++-----------------
 drivers/staging/etnaviv/etnaviv_gem.h        |  1 +
 drivers/staging/etnaviv/etnaviv_gem_prime.c  | 14 +++---
 drivers/staging/etnaviv/etnaviv_gem_submit.c | 12 ++---
 drivers/staging/etnaviv/etnaviv_gpu.c        |  2 +-
 drivers/staging/etnaviv/etnaviv_mmu.c        |  2 +
 8 files changed, 46 insertions(+), 57 deletions(-)

diff --git a/drivers/staging/etnaviv/etnaviv_drv.h b/drivers/staging/etnaviv/etnaviv_drv.h
index e31e899..d6bd438 100644
--- a/drivers/staging/etnaviv/etnaviv_drv.h
+++ b/drivers/staging/etnaviv/etnaviv_drv.h
@@ -75,7 +75,7 @@ int etnaviv_ioctl_gem_submit(struct drm_device *dev, void *data,
 int etnaviv_gem_mmap(struct file *filp, struct vm_area_struct *vma);
 int etnaviv_gem_fault(struct vm_area_struct *vma, struct vm_fault *vmf);
 int etnaviv_gem_mmap_offset(struct drm_gem_object *obj, u64 *offset);
-int etnaviv_gem_get_iova_locked(struct etnaviv_gpu *gpu,
+int etnaviv_gem_get_iova(struct etnaviv_gpu *gpu,
 	struct drm_gem_object *obj, u32 *iova);
 void etnaviv_gem_put_iova(struct etnaviv_gpu *gpu, struct drm_gem_object *obj);
 struct sg_table *etnaviv_gem_prime_get_sg_table(struct drm_gem_object *obj);
@@ -85,7 +85,6 @@ struct drm_gem_object *etnaviv_gem_prime_import_sg_table(struct drm_device *dev,
 	struct dma_buf_attachment *attach, struct sg_table *sg);
 int etnaviv_gem_prime_pin(struct drm_gem_object *obj);
 void etnaviv_gem_prime_unpin(struct drm_gem_object *obj);
-void *etnaviv_gem_vaddr_locked(struct drm_gem_object *obj);
 void *etnaviv_gem_vaddr(struct drm_gem_object *obj);
 int etnaviv_gem_cpu_prep(struct drm_gem_object *obj, u32 op,
 		struct timespec *timeout);
diff --git a/drivers/staging/etnaviv/etnaviv_dump.c b/drivers/staging/etnaviv/etnaviv_dump.c
index 9b0b0b0..bf8fa85 100644
--- a/drivers/staging/etnaviv/etnaviv_dump.c
+++ b/drivers/staging/etnaviv/etnaviv_dump.c
@@ -213,7 +213,7 @@ void etnaviv_core_dump(struct etnaviv_gpu *gpu)
 
 		iter.hdr->iova = cpu_to_le64(vram->iova);
 
-		vaddr = etnaviv_gem_vaddr_locked(&obj->base);
+		vaddr = etnaviv_gem_vaddr(&obj->base);
 		if (vaddr && !IS_ERR(vaddr))
 			memcpy(iter.data, vaddr, obj->base.size);
 
diff --git a/drivers/staging/etnaviv/etnaviv_gem.c b/drivers/staging/etnaviv/etnaviv_gem.c
index 0106c24..f853cf9 100644
--- a/drivers/staging/etnaviv/etnaviv_gem.c
+++ b/drivers/staging/etnaviv/etnaviv_gem.c
@@ -59,7 +59,7 @@ static void etnaviv_gem_scatterlist_unmap(struct etnaviv_gem_object *etnaviv_obj
 		dma_unmap_sg(dev->dev, sgt->sgl, sgt->nents, DMA_BIDIRECTIONAL);
 }
 
-/* called with dev->struct_mutex held */
+/* called with etnaviv_obj->lock held */
 static int etnaviv_gem_shmem_get_pages(struct etnaviv_gem_object *etnaviv_obj)
 {
 	struct drm_device *dev = etnaviv_obj->base.dev;
@@ -95,6 +95,8 @@ struct page **etnaviv_gem_get_pages(struct etnaviv_gem_object *etnaviv_obj)
 {
 	int ret;
 
+	lockdep_assert_held(&etnaviv_obj->lock);
+
 	if (!etnaviv_obj->pages) {
 		ret = etnaviv_obj->ops->get_pages(etnaviv_obj);
 		if (ret < 0)
@@ -123,6 +125,7 @@ struct page **etnaviv_gem_get_pages(struct etnaviv_gem_object *etnaviv_obj)
 
 void etnaviv_gem_put_pages(struct etnaviv_gem_object *etnaviv_obj)
 {
+	lockdep_assert_held(&etnaviv_obj->lock);
 	/* when we start tracking the pin count, then do something here */
 }
 
@@ -176,7 +179,7 @@ int etnaviv_gem_mmap(struct file *filp, struct vm_area_struct *vma)
 int etnaviv_gem_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
 {
 	struct drm_gem_object *obj = vma->vm_private_data;
-	struct drm_device *dev = obj->dev;
+	struct etnaviv_gem_object *etnaviv_obj = to_etnaviv_bo(obj);
 	struct page **pages, *page;
 	pgoff_t pgoff;
 	int ret;
@@ -186,13 +189,13 @@ int etnaviv_gem_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
 	 * something from beneath our feet.  Note that vm_insert_page() is
 	 * specifically coded to take care of this, so we don't have to.
 	 */
-	ret = mutex_lock_interruptible(&dev->struct_mutex);
+	ret = mutex_lock_interruptible(&etnaviv_obj->lock);
 	if (ret)
 		goto out;
 
 	/* make sure we have pages attached now */
-	pages = etnaviv_gem_get_pages(to_etnaviv_bo(obj));
-	mutex_unlock(&dev->struct_mutex);
+	pages = etnaviv_gem_get_pages(etnaviv_obj);
+	mutex_unlock(&etnaviv_obj->lock);
 
 	if (IS_ERR(pages)) {
 		ret = PTR_ERR(pages);
@@ -257,14 +260,7 @@ etnaviv_gem_get_vram_mapping(struct etnaviv_gem_object *obj,
 	return NULL;
 }
 
-/* should be called under struct_mutex.. although it can be called
- * from atomic context without struct_mutex to acquire an extra
- * iova ref if you know one is already held.
- *
- * That means when I do eventually need to add support for unpinning
- * the refcnt counter needs to be atomic_t.
- */
-int etnaviv_gem_get_iova_locked(struct etnaviv_gpu *gpu,
+int etnaviv_gem_get_iova(struct etnaviv_gpu *gpu,
 	struct drm_gem_object *obj, u32 *iova)
 {
 	struct etnaviv_gem_object *etnaviv_obj = to_etnaviv_bo(obj);
@@ -272,6 +268,7 @@ int etnaviv_gem_get_iova_locked(struct etnaviv_gpu *gpu,
 	struct page **pages;
 	int ret = 0;
 
+	mutex_lock(&etnaviv_obj->lock);
 	mapping = etnaviv_gem_get_vram_mapping(etnaviv_obj, gpu->mmu);
 	if (mapping) {
 		/*
@@ -296,8 +293,10 @@ int etnaviv_gem_get_iova_locked(struct etnaviv_gpu *gpu,
 	}
 
 	pages = etnaviv_gem_get_pages(etnaviv_obj);
-	if (IS_ERR(pages))
-		return PTR_ERR(pages);
+	if (IS_ERR(pages)) {
+		ret = PTR_ERR(pages);
+		goto out;
+	}
 
 	/*
 	 * See if we have a reaped vram mapping we can re-use before
@@ -326,6 +325,8 @@ int etnaviv_gem_get_iova_locked(struct etnaviv_gpu *gpu,
 		list_add_tail(&mapping->obj_node, &etnaviv_obj->vram_list);
 
 out:
+	mutex_unlock(&etnaviv_obj->lock);
+
 	if (!ret) {
 		/* Take a reference on the object */
 		drm_gem_object_reference(obj);
@@ -340,22 +341,21 @@ void etnaviv_gem_put_iova(struct etnaviv_gpu *gpu, struct drm_gem_object *obj)
 	struct etnaviv_gem_object *etnaviv_obj = to_etnaviv_bo(obj);
 	struct etnaviv_vram_mapping *mapping;
 
-	WARN_ON(!mutex_is_locked(&obj->dev->struct_mutex));
-
+	mutex_lock(&etnaviv_obj->lock);
 	mapping = etnaviv_gem_get_vram_mapping(etnaviv_obj, gpu->mmu);
 
 	WARN_ON(mapping->use == 0);
 	mapping->use -= 1;
+	mutex_unlock(&etnaviv_obj->lock);
 
 	drm_gem_object_unreference(obj);
 }
 
-void *etnaviv_gem_vaddr_locked(struct drm_gem_object *obj)
+void *etnaviv_gem_vaddr(struct drm_gem_object *obj)
 {
 	struct etnaviv_gem_object *etnaviv_obj = to_etnaviv_bo(obj);
 
-	WARN_ON(!mutex_is_locked(&obj->dev->struct_mutex));
-
+	mutex_lock(&etnaviv_obj->lock);
 	if (!etnaviv_obj->vaddr) {
 		struct page **pages = etnaviv_gem_get_pages(etnaviv_obj);
 
@@ -365,21 +365,11 @@ void *etnaviv_gem_vaddr_locked(struct drm_gem_object *obj)
 		etnaviv_obj->vaddr = vmap(pages, obj->size >> PAGE_SHIFT,
 				VM_MAP, pgprot_writecombine(PAGE_KERNEL));
 	}
+	mutex_unlock(&etnaviv_obj->lock);
 
 	return etnaviv_obj->vaddr;
 }
 
-void *etnaviv_gem_vaddr(struct drm_gem_object *obj)
-{
-	void *ret;
-
-	mutex_lock(&obj->dev->struct_mutex);
-	ret = etnaviv_gem_vaddr_locked(obj);
-	mutex_unlock(&obj->dev->struct_mutex);
-
-	return ret;
-}
-
 static inline enum dma_data_direction etnaviv_op_to_dma_dir(u32 op)
 {
 	if (op & ETNA_PREP_READ)
@@ -415,9 +405,9 @@ int etnaviv_gem_cpu_prep(struct drm_gem_object *obj, u32 op,
 		if (!etnaviv_obj->sgt) {
 			void *ret;
 
-			mutex_lock(&dev->struct_mutex);
+			mutex_lock(&etnaviv_obj->lock);
 			ret = etnaviv_gem_get_pages(etnaviv_obj);
-			mutex_unlock(&dev->struct_mutex);
+			mutex_unlock(&etnaviv_obj->lock);
 			if (IS_ERR(ret))
 				return PTR_ERR(ret);
 		}
@@ -534,12 +524,9 @@ static const struct etnaviv_gem_ops etnaviv_gem_shmem_ops = {
 
 void etnaviv_gem_free_object(struct drm_gem_object *obj)
 {
-	struct drm_device *dev = obj->dev;
 	struct etnaviv_gem_object *etnaviv_obj = to_etnaviv_bo(obj);
 	struct etnaviv_vram_mapping *mapping, *tmp;
 
-	WARN_ON(!mutex_is_locked(&dev->struct_mutex));
-
 	/* object should not be active */
 	WARN_ON(is_active(etnaviv_obj));
 
@@ -616,6 +603,7 @@ static int etnaviv_gem_new_impl(struct drm_device *dev, u32 size, u32 flags,
 		reservation_object_init(&etnaviv_obj->_resv);
 	}
 
+	mutex_init(&etnaviv_obj->lock);
 	INIT_LIST_HEAD(&etnaviv_obj->vram_list);
 
 	*obj = &etnaviv_obj->base;
@@ -772,12 +760,11 @@ static void __etnaviv_gem_userptr_get_pages(struct work_struct *_work)
 {
 	struct get_pages_work *work = container_of(_work, typeof(*work), work);
 	struct etnaviv_gem_object *etnaviv_obj = work->etnaviv_obj;
-	struct drm_device *dev = etnaviv_obj->base.dev;
 	struct page **pvec;
 
 	pvec = etnaviv_gem_userptr_do_get_pages(etnaviv_obj, work->mm, work->task);
 
-	mutex_lock(&dev->struct_mutex);
+	mutex_lock(&etnaviv_obj->lock);
 	if (IS_ERR(pvec)) {
 		etnaviv_obj->userptr.work = ERR_CAST(pvec);
 	} else {
@@ -785,8 +772,8 @@ static void __etnaviv_gem_userptr_get_pages(struct work_struct *_work)
 		etnaviv_obj->pages = pvec;
 	}
 
-	drm_gem_object_unreference(&etnaviv_obj->base);
-	mutex_unlock(&dev->struct_mutex);
+	mutex_unlock(&etnaviv_obj->lock);
+	drm_gem_object_unreference_unlocked(&etnaviv_obj->base);
 
 	mmput(work->mm);
 	put_task_struct(work->task);
diff --git a/drivers/staging/etnaviv/etnaviv_gem.h b/drivers/staging/etnaviv/etnaviv_gem.h
index dc2d94d..a300b4b 100644
--- a/drivers/staging/etnaviv/etnaviv_gem.h
+++ b/drivers/staging/etnaviv/etnaviv_gem.h
@@ -44,6 +44,7 @@ struct etnaviv_vram_mapping {
 struct etnaviv_gem_object {
 	struct drm_gem_object base;
 	const struct etnaviv_gem_ops *ops;
+	struct mutex lock;
 
 	u32 flags;
 
diff --git a/drivers/staging/etnaviv/etnaviv_gem_prime.c b/drivers/staging/etnaviv/etnaviv_gem_prime.c
index ac791fc..e94db4f 100644
--- a/drivers/staging/etnaviv/etnaviv_gem_prime.c
+++ b/drivers/staging/etnaviv/etnaviv_gem_prime.c
@@ -42,11 +42,11 @@ void etnaviv_gem_prime_vunmap(struct drm_gem_object *obj, void *vaddr)
 int etnaviv_gem_prime_pin(struct drm_gem_object *obj)
 {
 	if (!obj->import_attach) {
-		struct drm_device *dev = obj->dev;
+		struct etnaviv_gem_object *etnaviv_obj = to_etnaviv_bo(obj);
 
-		mutex_lock(&dev->struct_mutex);
-		etnaviv_gem_get_pages(to_etnaviv_bo(obj));
-		mutex_unlock(&dev->struct_mutex);
+		mutex_lock(&etnaviv_obj->lock);
+		etnaviv_gem_get_pages(etnaviv_obj);
+		mutex_unlock(&etnaviv_obj->lock);
 	}
 	return 0;
 }
@@ -54,11 +54,11 @@ int etnaviv_gem_prime_pin(struct drm_gem_object *obj)
 void etnaviv_gem_prime_unpin(struct drm_gem_object *obj)
 {
 	if (!obj->import_attach) {
-		struct drm_device *dev = obj->dev;
+		struct etnaviv_gem_object *etnaviv_obj = to_etnaviv_bo(obj);
 
-		mutex_lock(&dev->struct_mutex);
+		mutex_lock(&etnaviv_obj->lock);
 		etnaviv_gem_put_pages(to_etnaviv_bo(obj));
-		mutex_unlock(&dev->struct_mutex);
+		mutex_unlock(&etnaviv_obj->lock);
 	}
 }
 
diff --git a/drivers/staging/etnaviv/etnaviv_gem_submit.c b/drivers/staging/etnaviv/etnaviv_gem_submit.c
index e6011a8..189bbbd 100644
--- a/drivers/staging/etnaviv/etnaviv_gem_submit.c
+++ b/drivers/staging/etnaviv/etnaviv_gem_submit.c
@@ -205,8 +205,8 @@ static int submit_pin_objects(struct etnaviv_gem_submit *submit)
 		struct etnaviv_gem_object *etnaviv_obj = submit->bos[i].obj;
 		u32 iova;
 
-		ret = etnaviv_gem_get_iova_locked(submit->gpu,
-						  &etnaviv_obj->base, &iova);
+		ret = etnaviv_gem_get_iova(submit->gpu, &etnaviv_obj->base,
+					   &iova);
 		if (ret)
 			break;
 
@@ -331,7 +331,7 @@ int etnaviv_ioctl_gem_submit(struct drm_device *dev, void *data,
 
 	/*
 	 * Copy the command submission and bo array to kernel space in
-	 * one go, and do this outside of the dev->struct_mutex lock.
+	 * one go, and do this outside of any locks.
 	 */
 	bos = drm_malloc_ab(args->nr_bos, sizeof(*bos));
 	relocs = drm_malloc_ab(args->nr_relocs, sizeof(*relocs));
@@ -439,9 +439,9 @@ out:
 	etnaviv_gpu_pm_put(gpu);
 
 	/*
-	 * If we're returning -EAGAIN, it could be due to the userptr code
-	 * wanting to run its workqueue outside of the struct_mutex.
-	 * Flush our workqueue to ensure that it is run in a timely manner.
+	 * If we're returning -EAGAIN, it may be due to the userptr code
+	 * wanting to run its workqueue outside of any locks. Flush our
+	 * workqueue to ensure that it is run in a timely manner.
 	 */
 	if (ret == -EAGAIN)
 		flush_workqueue(priv->wq);
diff --git a/drivers/staging/etnaviv/etnaviv_gpu.c b/drivers/staging/etnaviv/etnaviv_gpu.c
index d751a29..192b0e9 100644
--- a/drivers/staging/etnaviv/etnaviv_gpu.c
+++ b/drivers/staging/etnaviv/etnaviv_gpu.c
@@ -1237,7 +1237,7 @@ int etnaviv_gpu_submit(struct etnaviv_gpu *gpu,
 		u32 iova;
 
 		/* Each cmdbuf takes a refcount on the iova */
-		etnaviv_gem_get_iova_locked(gpu, &etnaviv_obj->base, &iova);
+		etnaviv_gem_get_iova(gpu, &etnaviv_obj->base, &iova);
 		cmdbuf->bo[i] = etnaviv_obj;
 		atomic_inc(&etnaviv_obj->gpu_active);
 
diff --git a/drivers/staging/etnaviv/etnaviv_mmu.c b/drivers/staging/etnaviv/etnaviv_mmu.c
index a354efb..6743bc6 100644
--- a/drivers/staging/etnaviv/etnaviv_mmu.c
+++ b/drivers/staging/etnaviv/etnaviv_mmu.c
@@ -110,6 +110,8 @@ int etnaviv_iommu_map_gem(struct etnaviv_iommu *mmu,
 	struct drm_mm_node *node;
 	int ret;
 
+	lockdep_assert_held(&etnaviv_obj->lock);
+
 	mutex_lock(&mmu->lock);
 
 	/* v1 MMU can optimize single entry (contiguous) scatterlists */
-- 
2.6.2

